{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bd4fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T11:34:50.264258Z",
     "iopub.status.busy": "2024-02-04T11:34:50.263383Z",
     "iopub.status.idle": "2024-02-04T11:34:50.267517Z",
     "shell.execute_reply": "2024-02-04T11:34:50.266858Z",
     "shell.execute_reply.started": "2024-02-04T11:34:50.264222Z"
    },
    "tags": []
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec714c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.checks import FeatureDrift\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from catboost import (\n",
    "    CatBoostClassifier,\n",
    "    Pool, \n",
    "    cv, \n",
    "    EShapCalcType, \n",
    "    EFeaturesSelectionAlgorithm\n",
    ")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6e231",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a154acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205962, 235), (37183, 233))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv', sep=\";\", decimal=\",\", encoding=\"windows-1251\")\n",
    "test_df = pd.read_csv('data/test.csv', sep=\";\", decimal=\",\", encoding=\"windows-1251\")\n",
    "\n",
    "features_description = (\n",
    "    pd.read_excel('data/description.xlsx', index_col='field')\n",
    "    .to_dict()['description']\n",
    ")\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8241b05b",
   "metadata": {},
   "source": [
    "# Предварительный анализ EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "435df75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_df.drop(['client_id', 'feature_date', 'target', 'w'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767d510",
   "metadata": {},
   "source": [
    "### Поправляем типы данных для фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41101cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205962 entries, 0 to 205961\n",
      "Columns: 235 entries, client_id to productionyear\n",
      "dtypes: datetime64[ns](1), float64(223), int64(1), object(10)\n",
      "memory usage: 369.3+ MB\n"
     ]
    }
   ],
   "source": [
    "newtype_feats = [\n",
    "    'bki_total_ip_max_limit',\n",
    "    'hdb_bki_active_cc_cnt',\n",
    "    'hdb_bki_active_ip_max_outstand',\n",
    "    'hdb_bki_active_micro_max_outstand',\n",
    "    'hdb_bki_active_pil_max_overdue',\n",
    "    'hdb_bki_other_active_auto_month_payments_sum',\n",
    "    'hdb_bki_total_cc_max_limit',\n",
    "    'hdb_bki_total_ip_cnt',\n",
    "    'hdb_bki_total_max_limit',\n",
    "    'hdb_bki_total_max_overdue_sum',\n",
    "    'hdb_bki_total_pil_max_limit'\n",
    "]\n",
    "\n",
    "test_df[newtype_feats] = test_df[newtype_feats].astype('float64')\n",
    "test_df['feature_date'] = test_df['feature_date'].astype('datetime64[ns]')\n",
    "\n",
    "train_df[newtype_feats] = train_df[newtype_feats].astype('float64')\n",
    "train_df['feature_date'] = train_df['feature_date'].astype('datetime64[ns]')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12091ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 10, 221)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = list(train_df[features].select_dtypes('object').columns)\n",
    "num_features = list(set(features) - set(cat_features))\n",
    "\n",
    "len(features), len(cat_features), len(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f95c24",
   "metadata": {},
   "source": [
    "### Анализ категорильных фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd5bad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4184, 235)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько всего записей, где известна должность, но не известна зп?\n",
    "train_df.loc[\n",
    "    (train_df['worksalary_rur_amt'].isna())\n",
    "    & (~train_df['part_last_position_ccode'].isna())\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "303fd81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_last_position_ccode</th>\n",
       "      <th>median_worksalary_rur_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АВТОМЕХАНИК</td>\n",
       "      <td>158892.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>АДМИНИСТРАТОР</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>АНАЛИТИК</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Администратор</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Администратор магазина</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  part_last_position_ccode  median_worksalary_rur_amt\n",
       "0              АВТОМЕХАНИК                   158892.5\n",
       "1            АДМИНИСТРАТОР                   180000.0\n",
       "2                 АНАЛИТИК                   100000.0\n",
       "3            Администратор                    60000.0\n",
       "4   Администратор магазина                    70000.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df, содержащий медианные зарплаты для должностей по всем данным\n",
    "median_worksalary = (\n",
    "    pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "    .dropna(subset = 'worksalary_rur_amt')\n",
    "    .groupby('part_last_position_ccode', as_index=False)\n",
    "    ['worksalary_rur_amt'].median()\n",
    "    .rename(columns={'worksalary_rur_amt': 'median_worksalary_rur_amt'})\n",
    ")\n",
    "median_worksalary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abbb4e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 235)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.merge(median_worksalary, on='part_last_position_ccode', how='left')\n",
    "test_df['worksalary_rur_amt'] = test_df['worksalary_rur_amt'].fillna(test_df['median_worksalary_rur_amt'])\n",
    "test_df.drop('median_worksalary_rur_amt', axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.merge(median_worksalary, on='part_last_position_ccode', how='left')\n",
    "train_df['worksalary_rur_amt'] = train_df['worksalary_rur_amt'].fillna(train_df['median_worksalary_rur_amt'])\n",
    "train_df.drop('median_worksalary_rur_amt', axis=1, inplace=True)\n",
    "\n",
    "train_df.loc[\n",
    "    (train_df['worksalary_rur_amt'].isna())\n",
    "    & (~train_df['part_last_position_ccode'].isna())\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbac270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполняем пропуски в категориальных\n",
    "train_df['addrref'] = train_df['addrref'].fillna('Россия')\n",
    "test_df['addrref'] = test_df['addrref'].fillna('Россия')\n",
    "\n",
    "train_df[cat_features] = train_df[cat_features].fillna('miss_value')\n",
    "test_df[cat_features] = test_df[cat_features].fillna('miss_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46aab5e",
   "metadata": {},
   "source": [
    "# Инженерия фич"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0b165",
   "metadata": {},
   "source": [
    "### Фичи по датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc429a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем фичи из дат\n",
    "train_df['feature_date_year'] = train_df['feature_date'].dt.year\n",
    "train_df['feature_date_month'] = train_df['feature_date'].dt.month\n",
    "train_df['feature_date_day'] = train_df['feature_date'].dt.day\n",
    "\n",
    "test_df['feature_date_year'] = test_df['feature_date'].dt.year\n",
    "test_df['feature_date_month'] = test_df['feature_date'].dt.month\n",
    "test_df['feature_date_day'] = test_df['feature_date'].dt.day\n",
    "\n",
    "# машина\n",
    "train_df['car_old'] = train_df['feature_date_year'] - train_df['productionyear']\n",
    "train_df['car_country'] = train_df['brand']\n",
    "train_df.loc[\n",
    "    (train_df['car_country'].str.contains('LADA', flags=re.IGNORECASE))\n",
    "    | (train_df['car_country'].str.contains('ЛАДА', flags=re.IGNORECASE))\n",
    "    | (train_df['car_country'].isin(['МОСКВИЧ','КАМАЗ','ЗАЗ', 'ГАЗ'])),\n",
    "    'car_country'\n",
    "] = 'Россия'\n",
    "train_df.loc[\n",
    "    ~train_df['car_country'].isin(['miss_value', 'Россия']),\n",
    "    'car_country'\n",
    "] = 'Иномарка'\n",
    "\n",
    "test_df['car_old'] = test_df['feature_date_year'] - test_df['productionyear']\n",
    "test_df['car_country'] = test_df['brand']\n",
    "test_df.loc[\n",
    "    (test_df['car_country'].str.contains('LADA', flags=re.IGNORECASE))\n",
    "    | (test_df['car_country'].str.contains('ЛАДА', flags=re.IGNORECASE))\n",
    "    | (test_df['car_country'].isin(['МОСКВИЧ','КАМАЗ','ЗАЗ', 'ГАЗ'])),\n",
    "    'car_country'\n",
    "] = 'Россия'\n",
    "test_df.loc[\n",
    "    ~test_df['car_country'].isin(['miss_value', 'Россия']),\n",
    "    'car_country'\n",
    "] = 'Иномарка'\n",
    "\n",
    "# средняя, медианная, минимальная, максимальная зарплата по должности\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_median_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_mean_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_max_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_min_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_median_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_mean_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_max_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('part_last_position_ccode', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'position_min_worksalary_rur_amt'}),\n",
    "        on='part_last_position_ccode', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# средняя, медианная, минимальная, максимальная зарплата по месту жительства\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_median_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_mean_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_max_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_min_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_median_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_mean_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_max_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('addrref', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'addrref_min_worksalary_rur_amt'}),\n",
    "        on='addrref', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# средняя, медианная, минимальная, максимальная зарплата по сегменту\n",
    "train_df = (\n",
    "    train_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_median_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_mean_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_max_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_min_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "test_df = (\n",
    "    test_df\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].median()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_median_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].mean()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_mean_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].max()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_max_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    "    .merge(\n",
    "        pd.concat([train_df[features], test_df[features]], axis=0)\n",
    "        .groupby('segment', as_index=False)\n",
    "        ['worksalary_rur_amt'].min()\n",
    "        .rename(columns={'worksalary_rur_amt': 'segment_min_worksalary_rur_amt'}),\n",
    "        on='segment', \n",
    "        how='left'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41f2a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем создать новую фичу с среднемесячной суммой трат по известным категорям + выдача наличных в банкомате + среднемесячные платежи по кредитам(автокредиты)\n",
    "# Т.е. мы  объединяем все маловажные по значимости(около 0) фичи в одну общую, которая по итогам обучения получала от 7 до 15 места в списке значимости\n",
    "\n",
    "# Для создания этой фичи нам потребуются заполненные 0 значения Nan. Создадим копии исходных датафремов и заполним пропуски 0\n",
    "train_df2 = train_df[num_features].copy()\n",
    "test_df2 = test_df[num_features].copy()\n",
    "train_df2 = train_df2[num_features].fillna(0).astype(float)\n",
    "test_df2 = test_df2[num_features].fillna(0).astype(float)\n",
    "\n",
    "\n",
    "# Определяем колонки для суммирования по всем известным среднемесячным тратам\n",
    "columns_to_sum = [\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__bilety_na_kontserty_i_v_teatry',\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__brokerskie_uslugi',\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__hosting',\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__spa_sauny_bani',\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__tovary_dlja_detej',\n",
    "    'amount_by_category_30d__summarur_amt__sum__cashflowcategory_name__turisticheskie_agenstva',\n",
    "    'avg_3m_hotels',\n",
    "    'avg_6m_building_services',\n",
    "    'avg_6m_money_transactions',\n",
    "    'avg_6m_personal_services',\n",
    "    'avg_6m_transportation',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__detskie_igrushki',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__investitsii',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__odezhda_dlja_beremennyh',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__vydacha_nalichnyh_v_bankomate',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__zdorove',\n",
    "    'avg_by_category__amount__sum__cashflowcategory_name__zooparki',\n",
    "    'by_category__amount__sum__eoperation_type_name__platezh_cherez_vidzhet_moj_mobilnyj',\n",
    "    'by_category__amount__sum__eoperation_type_name__pokupka_paja',\n",
    "    'by_category__amount__sum__eoperation_type_name__vneshnij_perevod_rur',\n",
    "    'summarur_1m_miscellaneous_stores',\n",
    "    'summarur_1m_no_cat',\n",
    "    'hdb_bki_other_active_auto_month_payments_sum' # Средний платёж по автокредиту в других банках\n",
    "]\n",
    "feats_90_to_30 =[\n",
    "    'amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__marketplejsy',\n",
    "    'amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__nalogi',\n",
    "    'amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__ohota_i_rybalka',\n",
    "    'amount_by_category_90d__summarur_amt__sum__cashflowcategory_name__prochie_bilety'\n",
    "]\n",
    "train_df[feats_90_to_30] = train_df[feats_90_to_30]/3  # Приводим сумму за 90 дней к среднемесячным тратам за 30 дней\n",
    "columns_to_sum.extend(feats_90_to_30)\n",
    "\n",
    "# Считаем сумму трат за месяц по известным позициям\n",
    "train_df['new_avg_spending_30_days'] = train_df2[columns_to_sum].sum(axis=1)\n",
    "train_df['new_avg_spending_30_days'] = np.round(train_df['new_avg_spending_30_days']) # Округляем до целых чисел\n",
    "\n",
    "test_df['new_avg_spending_30_days'] = test_df2[columns_to_sum].sum(axis=1)\n",
    "test_df['new_avg_spending_30_days'] = np.round(test_df['new_avg_spending_30_days']) # Округляем до целых чисел\n",
    "\n",
    "# Заменям на NaN все 0 в нашей новой фиче\n",
    "train_df.loc[train_df['new_avg_spending_30_days'] == 0, 'new_avg_spending_30_days'] = np.nan\n",
    "test_df.loc[test_df['new_avg_spending_30_days'] == 0, 'new_avg_spending_30_days'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d668b1a",
   "metadata": {},
   "source": [
    "### Внешние фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1024670",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df = pd.read_csv('data/salary.csv', sep=\";\", decimal=\",\")\n",
    "salary_df = salary_df.set_index('Область')\n",
    "salary_df = salary_df.drop(['2018', '2019', '2020'], axis=1)\n",
    "salary_df = salary_df.rename(columns={\"2022\": \"avg_region_salary_2022\", \"2021\": \"avg_region_salary_2021\"})\n",
    "\n",
    "salary_month_df = pd.read_csv('data/salary_month.csv', sep=\";\", decimal=\",\")\n",
    "salary_month_df = salary_month_df.set_index('Область')\n",
    "\n",
    "vpm_df = pd.read_csv('data/vpm_2024.csv', sep=\";\", decimal=\",\")\n",
    "vpm_df = vpm_df.set_index('Область')\n",
    "vpm_df = vpm_df.rename(columns={\"2024\": \"vpm_2024\"})\n",
    "\n",
    "salary_rating_df = pd.read_csv('data/salary_rating.csv', sep=\";\", decimal=\",\")\n",
    "salary_rating_df = salary_rating_df.set_index('Область')\n",
    "\n",
    "rf_regions_df = pd.read_excel('data/RF_region.xlsx', decimal='.')\n",
    "\n",
    "index_of_life_df = pd.read_excel('data/isg_2012-2023.xlsx', decimal='.', sheet_name=1)\n",
    "index_of_life_df = pd.merge(index_of_life_df, rf_regions_df, on=['Город'], how='left')\n",
    "index_of_life_df = index_of_life_df.groupby(by='Регион', as_index=False)[[2022, 2023]].mean()\n",
    "index_of_life_df = index_of_life_df.rename(columns={'Регион': 'addrref'})\n",
    "index_of_life_df.loc[len(index_of_life_df.index )] = ['Россия', 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5446d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_salary_month_df = train_df.join(salary_month_df, on='addrref')\n",
    "client_salary_month_df['feature_date_month_year'] = client_salary_month_df['feature_date'].apply(lambda time: str(time.month) + '.' + str(time.year))\n",
    "client_salary_month_df['avg_salary_month'] = client_salary_month_df.apply(lambda x: x[x['feature_date_month_year']], axis=1)\n",
    "client_salary_month_df = client_salary_month_df[['client_id', 'avg_salary_month']]\n",
    "client_salary_month_df = client_salary_month_df.set_index('client_id')\n",
    "\n",
    "train_df = train_df.join(client_salary_month_df, on='client_id', how='left')\n",
    "train_df = train_df.join(vpm_df, on='addrref', how='left')\n",
    "train_df = train_df.join(salary_df, on='addrref', how='left')\n",
    "train_df = train_df.join(salary_rating_df, on='addrref', how='left')\n",
    "train_df = pd.merge(train_df, index_of_life_df, on=['addrref'], how='left')\n",
    "\n",
    "test_df = test_df.join(client_salary_month_df, on='client_id', how='left')\n",
    "test_df = test_df.join(vpm_df, on='addrref', how='left')\n",
    "test_df = test_df.join(salary_df, on='addrref', how='left')\n",
    "test_df = test_df.join(salary_rating_df, on='addrref', how='left')\n",
    "test_df = pd.merge(test_df, index_of_life_df, on=['addrref'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e1a2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205962, 263), (37183, 261))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73a6e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём 6 новых колонок на основе комбинации помесячной даты с (ключевой ставкой, инфляцией, курсом доллара)\n",
    "dates = sorted(train_df['feature_date'].unique())\n",
    "\n",
    "key_rate = [0.08, 0.07773, 0.075, 0.075, 0.075, 0.075, 0.075, 0.075, 0.075, 0.075, 0.075, 0.07786, 0.10478, 0.12476]\n",
    "inflation = [0.143, 0.1368, 0.1263, 0.1198, 0.1194, 0.1177, 0.1099, 0.0351, 0.0231, 0.0251, 0.0325, 0.043, 0.0515, 0.06]\n",
    "usd = [60.3919, 59.8215, 61.1158, 60.853, 65.815, 68.876, 72.7828, 76.0353, 80.9955, 79.2126, 83.3193, 90.474, 95.2853, 96.6223]\n",
    "\n",
    "# Создаём 4 новые колонки на основе комбинации помесячной даты с (денежной массы по данным центробанка)\n",
    "broad_money = [85693.0, 86137.8, 86655.5, 87797.6, 94715.5, 94495.6, 97054.6, 97775.0, 97850.4, 99238.6, 100918.6, 102686.8, 105446.2, 106149.3 ] # Широкая денежная масса млрд рублей\n",
    "broad_money_sa = [86072.7, 86684.4, 88206.7, 88950.2, 92377.3, 93214.9, 95150.8, 96519.8, 97722.5, 99925.5, 102253.4, 104046.6, 105877.8, 106871.4 ] # Широкая денежная масса млрд рублей сезонно скорректированная\n",
    "\n",
    "init_cols = train_df.columns\n",
    "\n",
    "for name, feature in zip(['key_rate', 'inflation', 'usd', 'broad_money', 'broad_money_sa'], [key_rate, inflation, usd, broad_money, broad_money_sa]):\n",
    "    \n",
    "    dates_dict = dict(map(lambda i,j : (i,j), dates, feature))\n",
    "    train_df['new_prev_month_avg_' + name] = train_df['feature_date'].apply(lambda x: dates_dict[x])\n",
    "    test_df['new_prev_month_avg_' + name] = [feature[-2]] * len(test_df)\n",
    "\n",
    "    dates_dict = dict(map(lambda i,j : (i,j), dates, feature[1:]))\n",
    "    train_df['new_this_month_avg_' + name] = train_df['feature_date'].apply(lambda x: dates_dict[x])\n",
    "    test_df['new_this_month_avg_' + name] = [feature[-1]] * len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b021f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 11, 258)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(train_df.drop(['client_id', 'feature_date', 'target', 'w'], axis=1).columns)\n",
    "\n",
    "cat_features = list(train_df[features].select_dtypes('object').columns)\n",
    "num_features = list(set(features) - set(cat_features))\n",
    "\n",
    "len(features), len(cat_features), len(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa11365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T11:47:59.711070Z",
     "iopub.status.busy": "2024-02-04T11:47:59.710649Z",
     "iopub.status.idle": "2024-02-04T11:47:59.714578Z",
     "shell.execute_reply": "2024-02-04T11:47:59.713936Z",
     "shell.execute_reply.started": "2024-02-04T11:47:59.711043Z"
    },
    "tags": []
   },
   "source": [
    "# Сохранение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bce5ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ml\\income-prediction-alfa-campus\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:189: UserWarning:\n",
      "\n",
      "The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.to_parquet('data/train.parquet')\n",
    "test_df.to_parquet('data/test.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
